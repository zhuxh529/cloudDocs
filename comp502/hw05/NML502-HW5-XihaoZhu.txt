%p1


   testX=10*rand(100,1);
   testX=sort(testX);
   testY=sin(testX)./testX;
  
   trainX=10*rand(400,1);
   trainX=sort(trainX);
   trainY=sin(trainX)./trainX;


   maxi=repmat(max(trainX), [size(trainX)(1),1]);
   mini=repmat(min(trainX), [size(trainX)(1),1]);
   trainX= (trainX-mini).*2 ./(maxi-mini) -1;

   maxy=repmat(max(trainY), [size(trainY)(1),1]);
   miny=repmat(min(trainY), [size(trainY)(1),1]);
   trainY= (trainY-miny).*2 ./(maxy-miny) -1;
   
   maxi=repmat(max(testX), [size(testX)(1),1]);
   mini=repmat(min(testX), [size(testX)(1),1]);
   testX= (testX-mini).*2 ./(maxi-mini) -1;

   maxy=repmat(max(testY), [size(testY)(1),1]);
   miny=repmat(min(testY), [size(testY)(1),1]);
   testY= (testY-miny).*2 ./(maxy-miny) -1;


   trainX=[ones(size(trainX)(1),1) trainX];
   testX=[ones(size(testX)(1),1) testX];


   paras=[0.2, 0.12,1, 20];

   [w,v,test, train]=BPlearn(150000, 10, trainX,trainY, testX, testY, paras);
   figure;
   hold on;
   plot(train*1.21/2); % scaling back to real abs err by muliplying 4.5
   plot(test*1.21/2, 'r');  % scaling back to real abs err by muliplying 4.5
   legend('train err','test err');
   title('P1,fold1 real absoulte error of my trained ANN');
   xlabel('x 200 steps');
   ylabel('y (real number)');

   hold off;
   disp("press enter to continue");
   pause;


   [err1, out]=BPrecall(w,v, 10, trainY, trainX, paras);
   figure;
   hold on;
   plot(trainX*5+5,(out+1)*1.21/2-0.21);
   plot(trainX*5+5,(trainY+1)*1.21/2-0.21,'r');
   legend('actual output','desired output');
   title('P1, fold1 actual output VS desired output');
   xlabel('x (real number)');
   ylabel('y (real number)');


   hold off;
   disp("press enter to continue");

   pause;
   figure;
   [err1, out]=BPrecall(w,v, 10, testY, testX, paras);
   




%p2


test=dlmread('test.txt');
testx=test(:,1:4);
testy=test(:, 5:7);
testy(testy==0)=-1;


aa=dlmread('irisdata3.txt');
y=aa(:,1:3);
x=aa(:,4:7);

	maxi=repmat(max(x), [size(x)(1),1]);
	mini=repmat(min(x), [size(x)(1),1]);
	x= (x-mini).*2 ./(maxi-mini) -1;

	maxi=repmat(max(testx), [size(testx)(1),1]);
	mini=repmat(min(testx), [size(testx)(1),1]);
	testx= (testx-mini).*2 ./(maxi-mini) -1;
testx=[ones(size(testx)(1),1) testx];

	paras=[0.9, 0.05,1, 200];


 	[w,v,test, train]=BPlearn(200000, 10, x,y,testx, testy, paras);
	figure;
 	hold on;
 	plot(train); % scaling back to real abs err by muliplying 4.5
 	plot(test, 'r');  % scaling back to real abs err by muliplying 4.5
 	legend('train err','test err');
 	title('P2, error');
 	xlabel('x 200 steps');
	ylabel('y (real number)');

 	hold off;



 	%p3

 	test=dlmread ('testData.txt');
testx=test(:,1:4);
testy=test(:, 5:7);
testy(testy==0)=-1;


aa=dlmread('trainData.txt');
y=aa(:,5:7);
x=aa(:,1:4);
y(y==0)=-1;

	maxi=repmat(max(x), [size(x)(1),1]);
	mini=repmat(min(x), [size(x)(1),1]);
	x= (x-mini).*2 ./(maxi-mini) -1;

	maxi=repmat(max(testx), [size(testx)(1),1]);
	mini=repmat(min(testx), [size(testx)(1),1]);
	testx= (testx-mini).*2 ./(maxi-mini) -1;

testx=[ones(size(testx)(1),1) testx];
x=[ones(size(x)(1),1) x];


	paras=[0.9, 0.05,1, 200];

	
	seq=unidrnd(size(testx)(1), [size(testx)(1)/3,1]);

 	[w,v,test, train]=BPlearn(100000, 10, x(seq',:),y(seq',:),testx(seq',:), testy(seq',:), paras);
	figure;
 	hold on;
 	plot(train); % scaling back to real abs err by muliplying 4.5
 	plot(test, 'r');  % scaling back to real abs err by muliplying 4.5
 	legend('train err','test err');
 	title('P3, fold 1 absolute average error');
 	xlabel('x 200 steps');
	ylabel('y (real absulute error)');

 	hold off;
 	
   	[err1, out]=BPrecall(w,v, 10, y(seq',:), x(seq',:), paras);
   	actual=getclass(out);
   	desire=getclass(y(seq',:));
   	figure;
 	hold on;
 	plot([1:25],actual,'ro');
 	plot([1:25],desire,'+');
 	title('fold 1 actual VS desired output');
 	xlabel('x');
	ylabel('class');
 	hold off;






 	seq=unidrnd(size(testx)(1), [size(testx)(1)/3,1]);

 	[w,v,test, train]=BPlearn(100000, 10, x(seq',:),y(seq',:),testx(seq',:), testy(seq',:), paras);
	figure;
 	hold on;
 	plot(train); % scaling back to real abs err by muliplying 4.5
 	plot(test, 'r');  % scaling back to real abs err by muliplying 4.5
 	legend('train err','test err');
 	title('P3, fold 2 absolute average error');
 	xlabel('x 200 steps');
	ylabel('y (real absulute error)');

 	hold off;

 	
   	[err1, out]=BPrecall(w,v, 10, y(seq',:), x(seq',:), paras);
   	actual=getclass(out);
   	desire=getclass(y(seq',:));
   	figure;
 	hold on;
 	plot([1:25],actual,'ro');
 	plot([1:25],desire,'+');
 	title('fold 2 actual VS desired output');
 	xlabel('x');
	ylabel('class');
 	hold off;


 	seq=unidrnd(size(testx)(1), [size(testx)(1)/3,1]);

 	[w,v,test, train]=BPlearn(100000, 10, x(seq',:),y(seq',:),testx(seq',:), testy(seq',:), paras);
	figure;
 	hold on;
 	plot(train); % scaling back to real abs err by muliplying 4.5
 	plot(test, 'r');  % scaling back to real abs err by muliplying 4.5
 	legend('train err','test err');
 	title('P3, fold 3 absolute average error');
 	xlabel('x 200 steps');
	ylabel('y (real absulute error)');

 	hold off;


   	[err1, out]=BPrecall(w,v, 10, y(seq',:), x(seq',:), paras);
   	actual=getclass(out);
   	desire=getclass(y(seq',:));
   	figure;
 	hold on;
 	plot([1:25],actual,'ro');
 	plot([1:25],desire,'+');
 	title('fold 3 actual VS desired output');
 	xlabel('x');
	ylabel('class');
 	hold off;





% BPlearn
function [w1,v1, mytest, mytrain]=BPlearn(n,s2,x,D, testX, testY, paras)
	
	mytest=[];
	mytrain=[];


	alpha=paras(1); % momentum term constant
	rate=paras(2); % learning rate
	slope=paras(3); % tanh slope
	epoch=paras(4); 


	m=6000;

	s1=size(x)(2);
	s3=size(D)(2);


	w=initWeights(s1,s2-1,0.02)
	v=initWeights(s2,s3,0.02)

	dw_prev=zeros(s1,s2-1);
	dv_prev=zeros(s2,s3);


for i=1:n

	no=randi(size(x)(1));
	input =x(no, :);
	y1=input*w;
	y1=tanh(slope*y1);
	y1=[1 y1];
	y2=tanh(slope*y1*v);
	%size(y1)
	err2=(D(no,:) -y2).*(1-y2.^2);
	err1=v(2:s2,:)*err2'.*(1-y1(2:s2)'.^2);

	dv=rate*y1'*err2;
	dv_prev=dv;


	dw=rate*repmat(x(no,:)', [1,s2-1]).*repmat(err1',[s1,1]);
	dw_prev=dw;

	if rem(i,epoch)==0
		w=w+dw;
		v=v+dv;
		wtemp=w;
		vtemp=v;
		[err_train, o1]=BPrecall(wtemp,vtemp,10,D,x,paras);
		%disp(err_train);
		wtemp1=w;
		vtemp1=v;
		[err_test,o2]=BPrecall(wtemp1,vtemp1,10,testY,testX,paras);
		%str=[num2str(err_train) '       ' num2str(err_test)];
		%disp(str);
		mytest=[mytest err_test];
		mytrain=[mytrain err_train];
		
		
		


	end

	if rem(i,m)==0
		str = [ num2str(i) '       ' num2str(input) '       ' num2str(D(no,:)) '       ' num2str(y2) '       ' num2str(D(no,:)-y2)]; 
		disp(str);
		
	end


end
	w1=w;
	v1=v;


end




%BPrecall
function [err, out]=BPrecall(w,v, s2, D, train, paras)
	alpha=paras(1); % momentum term constant
	rate=paras(2); % learning rate
	slope=paras(3); % tanh slope
	epoch=paras(4); 

	x=train;
	s1=size(x)(2)+1;
	s3=size(D)(2);

	%	x=[ones(size(x)(1),1) x];

	out=[];

for no=1:size(x)(1)
	%no=randi(size(x)(1));
	input =x(no, :);
	y1=input*w;
	y1=tanh(slope*y1);
	y1=[1 y1];
	y2=tanh(slope*y1*v);
	y2(y2>0.3)=1;
	y2(y2<-0.3)=-1;
	out=[out; y2];
end
	err=abs(D.-out);
	err=sum(sum(err))/size(D)(1);

end

